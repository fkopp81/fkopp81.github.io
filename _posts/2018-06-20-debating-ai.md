---
Date: '2018-06-20 20:58 +0200'
published: false
title: Debating AI
---
# Debating AI

I have argued with (read: shouted at) misbehaving computers before, but this takes it to the next level:

[IBM's AI can beat humans in an argument](https://www.axios.com/ibms-ai-can-beat-humans-in-an-argument-a64bf953-c0b0-441c-bc09-e2b2ea6076f1.html)

The [Project Debater AI](https://www.research.ibm.com/artificial-intelligence/project-debater/) learns from news and scientific articles and can draw from them to eloquently discuss topics.

It's reminiscent of a homunculus. A human-like entity without an agenda of it's own who you can call upon to talk with you at length. But in the end it is an aggregator of what it's been fed, not a source of truth. How will the information be weighed between opposing sources? Can it understand outdated and disproved information?

Can it be convinced and change it's stance when encountering a better argument?

On the other hand - can we reliably? I Looking at the current political discourse it doesn't seem like it. Even in science new theories  sometimes gain traction as generations of scientists change.

Maybe getting an AI to just be better than humans at evolving it's position will be a low hanging fruit.





A New Post

Enter text in [Markdown](http://daringfireball.net/projects/markdown/). Use the toolbar above, or click the **?** button fo formatting help.